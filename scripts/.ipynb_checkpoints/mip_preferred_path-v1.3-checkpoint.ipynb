{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8950125e",
   "metadata": {},
   "source": [
    "## MIP Program for choosing preferred path for ancestor nodes.\n",
    "1. Program - Gurobi Solver\n",
    "2. Date - 5 September 2022\n",
    "3. Add each ancestor POG as constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fdbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import gurobipy as gp\n",
    "from gurobipy import abs_,quicksum\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from ete3 import Tree\n",
    "import numpy as np\n",
    "from pysam import FastaFile\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026583a",
   "metadata": {},
   "source": [
    "## MIP INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1c8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Convert the json pogs file to the data structure needed for MIP Model'''\n",
    "''' Information needed \n",
    "extant list - list of all extant nodes\n",
    "sequence length\n",
    "total nodes in the tree\n",
    "edges from position in the node\n",
    "edges to the position in the node\n",
    "fully connected, start, end, single connected and unconnected positions\n",
    "'''\n",
    "\n",
    "\n",
    "class Pogs:\n",
    "    def __init__(self,pogs_file,tree_file):\n",
    "        \n",
    "        self.json_pogs_file = pogs_file\n",
    "        tree_file = open(nwk_file_path,\"r\")\n",
    "        my_tree = tree_file.read() + \";\"\n",
    "        self.tree = Tree(my_tree, format=1)\n",
    "        self.node_path_dict = {}\n",
    "        self.node_path_reverse_dict = {}\n",
    "        self.tree_neighbor_dict = defaultdict(list)\n",
    "        self.node_type_dict = defaultdict(list)\n",
    "        self.node_pogs_cnt = {}\n",
    "        self.node_pogs = {}\n",
    "        self.extant_list = []\n",
    "        self.nodes = 0\n",
    "          \n",
    "    def count_path(self,a):\n",
    "        ''' count the number of paths in a graph '''\n",
    "        a = a + a.T    #add up the transpose\n",
    "        a = np.clip(a,0,1)\n",
    "        a = np.triu(a) #only the upper triangle\n",
    "\n",
    "        nodes = a.shape[0]\n",
    "        dp = [0] * nodes\n",
    "        dp[nodes - 1]= 1 #last node\n",
    "\n",
    "        for i in range(nodes - 1, -1, -1):\n",
    "            neighbour_nodes = np.where (a[i] == 1)[0]\n",
    "            for j in neighbour_nodes:\n",
    "                dp[i] = dp[i] + dp[j]\n",
    "\n",
    "        return(dp[0])\n",
    "    \n",
    "    def create_neighbor_object(self):\n",
    "        ''' create neighbor dict '''\n",
    "        \n",
    "        for n in self.tree.traverse():\n",
    "            if n.is_leaf() == False:    \n",
    "                for c in n.children:\n",
    "                    self.tree_neighbor_dict[n.name] += [c.name]\n",
    "        return self.tree_neighbor_dict\n",
    "                \n",
    "    def create_node_info_dict(self):\n",
    "        ''' create edge dictionary and other node information'''\n",
    "        '''Example output-- {\\\n",
    "                  1:{0:[1,2],1:[2,3,4],2:[3,4],3:[4],4:[5]} ,\\\n",
    "                  2:{0:[1],1:[2],2:[3],3:[4],4:[5]} \\\n",
    "                  } '''\n",
    "        # read the json file\n",
    "        with open(self.json_pogs_file, 'r') as j:\n",
    "            pog_all_data = json.loads(j.read())\n",
    "\n",
    "            # read all ancestors\n",
    "            for node_type in ['Ancestors','Extants']:\n",
    "                for pog_data in pog_all_data[node_type]:\n",
    "                    if node_type == 'Ancestors':\n",
    "                        node_name = 'N' + pog_data['Name']\n",
    "                    else:\n",
    "                        node_name = pog_data['Name']\n",
    "                        \n",
    "                    node_edges_info_dict = defaultdict(list)\n",
    "                    node_edges_reverse_info_dict = defaultdict(list)\n",
    "                    \n",
    "                    # read that node's data\n",
    "                    self.nodes = pog_data['Size'] + 2\n",
    "                    mat = np.zeros(shape=(self.nodes,self.nodes))\n",
    "                    \n",
    "                    # Edges from special Start node to the start nodes\n",
    "                    for s in pog_data['Starts']:\n",
    "                        node_edges_info_dict[0] += [s+1] \n",
    "                        node_edges_reverse_info_dict[s+1] += [0]\n",
    "                        mat[0,s + 1] = 1\n",
    "                       \n",
    "                    # Edges from last node to the special End node\n",
    "                    for e in pog_data['Ends']:\n",
    "                        node_edges_info_dict[e + 1] += [self.nodes-1]\n",
    "                        node_edges_reverse_info_dict[self.nodes-1] += [e + 1]\n",
    "                        mat[e + 1,self.nodes-1] = 1\n",
    "                        \n",
    "                        \n",
    "                    # create the adjency matrix for all nodes except from special node start\n",
    "                    for ind,node in enumerate(pog_data['Indices']):\n",
    "                        row_mat = node\n",
    "                        row_col = pog_data['Adjacent'][ind]\n",
    "\n",
    "                        for rc in row_col:\n",
    "                            node_edges_info_dict[row_mat + 1] += [rc + 1]\n",
    "                            node_edges_reverse_info_dict[rc + 1] += [row_mat + 1]\n",
    "                            mat[row_mat + 1,rc + 1] = 1\n",
    "                            \n",
    "                    # put all info together in the final dict\n",
    "                    self.node_path_dict[node_name] = node_edges_info_dict\n",
    "                    self.node_path_reverse_dict[node_name] = node_edges_reverse_info_dict\n",
    "                    \n",
    "                    # number of paths in pog\n",
    "                    total_sequences = self.count_path(mat)\n",
    "                    self.node_pogs_cnt[node_name] = total_sequences\n",
    "                    self.node_pogs[node_name] = mat\n",
    "                    \n",
    "                    # add nodes with only 1 path in pogs in the extant list\n",
    "                    if total_sequences == 1:\n",
    "                        self.extant_list.append(node_name)  # all extants\n",
    "                    if total_sequences == 0:\n",
    "                        print(\"ERROR:: There is no path in the POG\")\n",
    "                    \n",
    "        return self.node_path_dict,self.node_path_reverse_dict,self.nodes,self.extant_list,self.node_pogs_cnt,\\\n",
    "                                                                                        self.node_pogs\n",
    "    \n",
    "    def node_type_info(self):\n",
    "        ''' different node type information , to make it easier for MIP coding'''\n",
    "        \n",
    "        for node_name,node_edge_val in self.node_path_dict.items():\n",
    "            self.node_type_dict[(node_name,'start')] = [0]\n",
    "            self.node_type_dict[(node_name,'end')] = [self.nodes - 1]\n",
    "            positions = self.nodes\n",
    "            forward_edges = self.node_path_dict[node_name]\n",
    "            backward_edges = self.node_path_reverse_dict[node_name]\n",
    "            \n",
    "            for n in range(1,positions - 1):   # do not include start / end positions\n",
    "                if forward_edges.get(n) and backward_edges.get(n):\n",
    "                    self.node_type_dict[(node_name,'fc_nodes')]   += [n]\n",
    "                elif (forward_edges.get(n) and not backward_edges.get(n)):\n",
    "                    self.node_type_dict[(node_name,'f_sc_nodes')] += [n]\n",
    "                elif (not forward_edges.get(n) and backward_edges.get(n)):\n",
    "                    self.node_type_dict[(node_name,'t_sc_nodes')] += [n] \n",
    "                else:\n",
    "                    self.node_type_dict[(node_name,'uc_nodes')]   += [n]\n",
    "        return self.node_type_dict\n",
    "            \n",
    "## testing\n",
    "#nwk_file_path = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/sample_tree/grasp_ancestors.nwk'\n",
    "#pogs_file     = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/sample_tree/pogs.json'\n",
    "#p = Pogs(pogs_file,nwk_file_path)\n",
    "#p.create_node_info_dict()\n",
    "#p.create_neighbor_object()\n",
    "#p.node_type_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c1591",
   "metadata": {},
   "source": [
    "## MIP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f200c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' MIP Model for preferred path with least parsimonous score \n",
    "\n",
    "CONSTRAINTS\n",
    "\n",
    "EDGES - (ANCESTOR NODE ONLY)\n",
    "1. possible_edge_constraint : edge is present and sum of all edges <= 1\n",
    "2. na_edge_constraint       : edge is not present\n",
    "3. edge_recon_constraint    : sum of the edges coming in is equal sum of edges going out ( not for start/end position)\n",
    "\n",
    "POSITION - (ANCESTOR + EXTANTS)\n",
    "1. extant_position_constraint     : fixed constraint if the position is present in extant\n",
    "2. start_end_position_constraint  : start and end position contraint fixed and == 1\n",
    "3. edge_from_constraint           : sum(of all going out edges) == position variable\n",
    "4. edge_to_constraint             : sum(of all coming in edges) == position variable\n",
    "5. unconnected_position_constraint: position in the node not connected to any other nodes\n",
    "\n",
    "DIFFERENCE - (NEIGHBORS)\n",
    "1. pos_diff_constraint : difference in each position betweeen node and its neighbors\n",
    "\n",
    "PENALTY - (NEIGHBORS)\n",
    "1. penalty_constraint  : penalty varaible constraint. it is 1 for every opening difference between positions.\n",
    "\n",
    "'''\n",
    "\n",
    "class PhyloTree:\n",
    "    def __init__(self,nodes,sequence_length,neighbor_dict,node_from_edge_dict,folder_location\\\n",
    "                 ,extant_list,tree_name,position_type_dict,node_from_reverse_edge_dict):\n",
    "\n",
    "        # Define the configuration  and decision variables for the tree\n",
    "        self.nodes = nodes\n",
    "        self.sequence_length = sequence_length\n",
    "        self.neighbor_dict = neighbor_dict\n",
    "        self.node_from_edge_dict = node_from_edge_dict\n",
    "        self.folder_location = folder_location\n",
    "        self.extant_list = extant_list\n",
    "        self.tree_name = tree_name\n",
    "        self.position_type_dict = position_type_dict\n",
    "        self.node_from_reverse_edge_dict = node_from_reverse_edge_dict\n",
    "        \n",
    "        # MIP data structures\n",
    "        self.edges = {}\n",
    "        self.positions = {}\n",
    "        self.penalty = {}\n",
    "        self.diff = {}\n",
    "        self.objective = []\n",
    "        self.M = 999\n",
    "\n",
    "        # 2 - create a new model\n",
    "        self.m = gp.Model(\"PreferredPathSolve\")\n",
    "        \n",
    "        \n",
    "    def add_edges_var_constraints(self):\n",
    "        ''' add edge varaibles and constraints for ancestor nodes only '''  \n",
    "    \n",
    "        for node,node_edge_from_list in self.node_from_edge_dict.items():\n",
    "            \n",
    "            # node type ( edges for ancestor nodes)\n",
    "            if node not in self.extant_list:\n",
    "                \n",
    "                # fully connected positions\n",
    "                if self.position_type_dict.get((node,'fc_nodes')):\n",
    "                    for pos_from in self.position_type_dict.get((node,'fc_nodes')):\n",
    "                        all_edges_from_pos = []\n",
    "                        for pos_to in node_edge_from_list[pos_from]:\n",
    "                            edge_id = (node,pos_from,pos_to)\n",
    "                            e = self.m.addVar(vtype=GRB.BINARY, name='e-%s-%s-%s'%edge_id)\n",
    "                            self.edges[edge_id] = e\n",
    "                            all_edges_from_pos.append(e)\n",
    "                        \n",
    "                        # only 1 edge can be used\n",
    "                        pos_id = (node,pos_from)\n",
    "                        self.m.addConstr(quicksum(all_edges_from_pos) <= 1,name=\\\n",
    "                                                  \"possible_edge_constraint-%s-%s\"%pos_id)\n",
    "                    \n",
    "                # start position\n",
    "                if self.position_type_dict.get((node,'start')):\n",
    "                    for pos_from in self.position_type_dict.get((node,'start')):\n",
    "                        all_edges_from_pos = []\n",
    "                        for pos_to in node_edge_from_list[pos_from]:\n",
    "                            edge_id = (node,pos_from,pos_to)\n",
    "                            e = self.m.addVar(vtype=GRB.BINARY, name='e-%s-%s-%s'%edge_id)\n",
    "                            self.edges[edge_id] = e\n",
    "                            all_edges_from_pos.append(e)\n",
    "                            \n",
    "                        # only 1 edge can be used\n",
    "                        pos_id = (node,pos_from)\n",
    "                        self.m.addConstr(quicksum(all_edges_from_pos) <= 1,\\\n",
    "                                            name = \"possible_edge_constraint-%s-%s\"%pos_id)\n",
    "                        self.m.addConstr(quicksum(all_edges_from_pos) == self.positions[pos_id],\\\n",
    "                                            name = \"edge_from_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                # end position\n",
    "                if self.position_type_dict.get((node,'end')):\n",
    "                    for pos_to in self.position_type_dict.get((node,'end')):\n",
    "                        all_edges_to_pos = []\n",
    "                        for pos_from in node_from_reverse_edge_dict[node][pos_to]:\n",
    "                            edge_id = (node,pos_from,pos_to)\n",
    "                            all_edges_to_pos.append(self.edges[edge_id])\n",
    "                            \n",
    "                        # only 1 edge can be used\n",
    "                        pos_id = (node,pos_to)\n",
    "                        self.m.addConstr(quicksum(all_edges_to_pos) <= 1,\\\n",
    "                                           name  = \"possible_edge_constraint-%s-%s\"%pos_id)\n",
    "                        self.m.addConstr(quicksum(all_edges_to_pos) == self.positions[pos_id],\\\n",
    "                                            name = \"edge_to_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                \n",
    "                # one way edges - only forward\n",
    "                if self.position_type_dict.get((node,'f_sc_nodes')):\n",
    "                    for pos_from in self.position_type_dict.get((node,'f_sc_nodes')):\n",
    "                        \n",
    "                        all_edges_from_pos = []\n",
    "                        for pos_to in node_edge_from_list[pos_from]:\n",
    "                            edge_id = (node,pos_from,pos_to)\n",
    "                            e = self.m.addVar(vtype=GRB.BINARY, name='e-%s-%s-%s'%edge_id)\n",
    "                            self.edges[edge_id] = e\n",
    "                            all_edges_from_pos.append(e)\n",
    "                            \n",
    "                        # only 1 edge can be used\n",
    "                        pos_id = (node,pos_from)\n",
    "                        self.m.addConstr(quicksum(all_edges_from_pos) <= 1,name=\\\n",
    "                                                     \"possible_edge_constraint-%s-%s\"%pos_id)\n",
    "\n",
    "                        edge_id = (node,0,pos_from)\n",
    "                        e = self.m.addVar(vtype=GRB.BINARY, name='e-%s-%s-%s'%edge_id)\n",
    "                        self.edges[edge_id] = e\n",
    "                        \n",
    "                        # fake edge\n",
    "                        self.m.addConstr(self.edges[edge_id] == 0,name=\\\n",
    "                                                 \"na_edge_constraint-%s-%s-%s\"%edge_id)\n",
    "                # one way edges - coming in\n",
    "                if self.position_type_dict.get((node,'t_sc_nodes')):\n",
    "                    for pos_from in self.position_type_dict.get((node,'t_sc_nodes')):\n",
    "                        \n",
    "                        edge_id = (node,pos_from, sequence_length - 1)\n",
    "                        e = self.m.addVar(vtype=GRB.BINARY, name='e-%s-%s-%s'%edge_id)\n",
    "                        self.edges[edge_id] = e \n",
    "                        \n",
    "                        # fake edge\n",
    "                        self.m.addConstr(self.edges[edge_id] == 0,name=\\\n",
    "                                                 \"na_edge_constraint-%s-%s-%s\"%edge_id)\n",
    "            \n",
    "    def add_pos_var_constraints(self):     \n",
    "        ''' add position, diff and penalty variables. add diff constraints'''\n",
    "    \n",
    "        # position constraints\n",
    "        for node,node_edge_from_list in self.node_from_edge_dict.items():\n",
    "            for pos_from in range(0,sequence_length):\n",
    "                pos_id = (node,pos_from)\n",
    "                pos = self.m.addVar(vtype=GRB.BINARY, name=\"n-%s-%s\"%pos_id)\n",
    "                self.positions[pos_id] = pos\n",
    "                \n",
    "                # special constraint for start and end node\n",
    "                if pos_from == 0 or pos_from == self.sequence_length - 1:\n",
    "                    self.m.addConstr(self.positions[pos_id] == 1,\\\n",
    "                                     name=\"start_end_position_constraint-%s-%s\"%pos_id)\n",
    "\n",
    "        for node,node_neighbor in self.neighbor_dict.items():\n",
    "            for node_neighbor_item in node_neighbor:\n",
    "                for pos in range(1,sequence_length - 1): # penalty start from 1st position only\n",
    "                    \n",
    "                    # penalty variables\n",
    "                    pen_id = (node,node_neighbor_item,pos)\n",
    "                    pen = self.m.addVar(vtype=GRB.BINARY, name='p-%s-%s-%s'%pen_id)\n",
    "                    self.penalty[pen_id] = pen\n",
    "\n",
    "                    # add position difference to the objective (not for start and end node)\n",
    "                    node_pos_var = self.positions[(node,pos)]\n",
    "                    node_neighbor_pos_var = self.positions[(node_neighbor_item,pos)]\n",
    "                    diff_id = (node,node_neighbor_item,pos)\n",
    "                    diff_pos = self.m.addVar(vtype=GRB.BINARY, name='d-%s-%s-%s'%diff_id)\n",
    "                    self.diff[diff_id] = diff_pos\n",
    "\n",
    "                    # abs difference constraint\n",
    "                    self.m.addConstr( diff_pos <= node_pos_var + node_neighbor_pos_var,name=\\\n",
    "                                     \"diff_constraint_1-%s-%s-%s\"%(node,node_neighbor_item,pos))\n",
    "                    self.m.addConstr( diff_pos >= node_pos_var - node_neighbor_pos_var,name=\\\n",
    "                                     \"diff_constraint_2-%s-%s-%s\"%(node,node_neighbor_item,pos))\n",
    "                    self.m.addConstr( diff_pos >= node_neighbor_pos_var - node_pos_var,name=\\\n",
    "                                     \"diff_constraint_3-%s-%s-%s\"%(node,node_neighbor_item,pos))\n",
    "                    self.m.addConstr( diff_pos <= 2 - node_neighbor_pos_var - node_pos_var,name=\\\n",
    "                                     \"diff_constraint_4-%s-%s-%s\"%(node,node_neighbor_item,pos))\n",
    "                    self.objective.append(diff_pos)\n",
    "                    \n",
    "        \n",
    "        \n",
    "    def add_pos_constraints_extants(self):\n",
    "        ''' function to add constraints for extants to fix them '''\n",
    "\n",
    "        for node in self.extant_list:\n",
    "            extant_node_edges_forward = self.node_from_edge_dict[node]\n",
    "            position_present = list(extant_node_edges_forward.keys())\n",
    "            position_present.append(self.sequence_length - 1) # last position\n",
    "            \n",
    "            for pos_from in range(0,sequence_length):\n",
    "                pos_id = (node,pos_from)\n",
    "                if pos_from in position_present:\n",
    "                    self.m.addConstr(self.positions[pos_id] == 1,\\\n",
    "                                     name=\"extant_position_constraint-%s-%s\"%pos_id)\n",
    "                else:\n",
    "                        self.m.addConstr(self.positions[pos_id] == 0,\\\n",
    "                                     name=\"extant_position_constraint-%s-%s\"%pos_id)\n",
    "                \n",
    "                        \n",
    "    def add_constraints_ancestors(self):\n",
    "        ''' function to add constraints for ancestor node '''\n",
    "        \n",
    "        for node,node_edge_from_list in self.node_from_edge_dict.items():\n",
    "            \n",
    "            # node type ( edges for ancestor nodes)\n",
    "            if node not in self.extant_list:\n",
    "                \n",
    "                # unconnected positions\n",
    "                if self.position_type_dict.get((node,'uc_nodes')):\n",
    "                    for pos_from in self.position_type_dict.get((node,'uc_nodes')):\n",
    "                        pos_id = (node,pos_from)\n",
    "                        \n",
    "                        self.m.addConstr(self.positions[pos_id] == 0,\\\n",
    "                                     name=\"unconnected_position_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                # fully connected positions\n",
    "                if self.position_type_dict.get((node,'fc_nodes')):\n",
    "                    for pos_from in self.position_type_dict.get((node,'fc_nodes')):\n",
    "                        \n",
    "                        # edges coming in\n",
    "                        edges_coming_in = node_from_reverse_edge_dict[node][pos_from]\n",
    "                        #edges going out\n",
    "                        edges_going_out = node_edge_from_list[pos_from]\n",
    "                    \n",
    "                        # get all edges going out and coming in\n",
    "                        edges_coming_in_list = []\n",
    "                        edges_going_out_list = []\n",
    "\n",
    "                        for edges_coming_in_item in edges_coming_in:\n",
    "                            edge_to_id = (node,edges_coming_in_item,pos_from)\n",
    "                            edges_coming_in_list.append(self.edges[edge_to_id])\n",
    "\n",
    "                        for edges_going_out_item in edges_going_out:\n",
    "                            edge_to_id = (node,pos_from,edges_going_out_item)\n",
    "                            edges_going_out_list.append(self.edges[edge_to_id])\n",
    "\n",
    "                        pos_id = (node,pos_from)\n",
    "                        self.m.addConstr(sum(edges_coming_in_list) == sum(edges_going_out_list),\\\n",
    "                                                 name=\"edge_recon_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                        self.m.addConstr(sum(edges_going_out_list) == self.positions[pos_id],\\\n",
    "                                            name=\"edge_from_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                        self.m.addConstr(sum(edges_coming_in_list) == self.positions[pos_id],\\\n",
    "                                            name=\"edge_to_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                        \n",
    "                # single connected positions\n",
    "                # one way edges - only forward\n",
    "                if self.position_type_dict.get((node,'f_sc_nodes')):\n",
    "                    for pos_from in self.position_type_dict.get((node,'f_sc_nodes')):\n",
    "                        \n",
    "                        #edges going out\n",
    "                        edges_going_out = node_edge_from_list[pos_from]\n",
    "                        edges_going_out_list = []\n",
    "                        \n",
    "                        for edges_going_out_item in edges_going_out:\n",
    "                            edge_to_id = (node,pos_from,edges_going_out_item)\n",
    "                            edges_going_out_list.append(self.edges[edge_to_id])\n",
    "                            \n",
    "                        edge_id = (node,0,pos_from) \n",
    "                        pos_id = (node,pos_from)\n",
    "                        self.m.addConstr(sum(edges_going_out_list) == self.edges[edge_id],\\\n",
    "                                                 name=\"edge_recon_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                        self.m.addConstr(sum(edges_going_out_list) == self.positions[pos_id],\\\n",
    "                                            name=\"edge_from_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                        self.m.addConstr(self.edges[edge_id] == self.positions[pos_id],\\\n",
    "                                            name=\"edge_to_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                    \n",
    "                # one way edges - coming in\n",
    "                if self.position_type_dict.get((node,'t_sc_nodes')):\n",
    "                    for pos_from in self.position_type_dict.get((node,'t_sc_nodes')):\n",
    "                        \n",
    "                        # edges coming in\n",
    "                        edges_coming_in = node_from_reverse_edge_dict[node][pos_from]\n",
    "                        edges_coming_in_list = []\n",
    "                        \n",
    "                        for edges_coming_in_item in edges_coming_in:\n",
    "                            edge_to_id = (node,edges_coming_in_item,pos_from)\n",
    "                            edges_coming_in_list.append(self.edges[edge_to_id])\n",
    "                            \n",
    "                        \n",
    "                        edge_id = (node,pos_from, sequence_length - 1) \n",
    "                        pos_id = (node,pos_from)\n",
    "                        self.m.addConstr(sum(edges_coming_in_list) == self.edges[edge_id],\\\n",
    "                                                 name=\"edge_recon_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                        self.m.addConstr(sum(edges_coming_in_list) == self.positions[pos_id],\\\n",
    "                                            name=\"edge_to_constraint-%s-%s\"%pos_id)\n",
    "                        \n",
    "                        self.m.addConstr(self.edges[edge_id] == self.positions[pos_id],\\\n",
    "                                            name=\"edge_from_constraint-%s-%s\"%pos_id)       \n",
    "             \n",
    "    def penalty_constraints(self):\n",
    "        ''' function to add penalty constraints '''\n",
    "        \n",
    "        for node,node_neighbor in self.neighbor_dict.items():\n",
    "            for node_neighbor_item in node_neighbor:\n",
    "                for pos in range(1,sequence_length - 1):  # no penalty for start and end\n",
    "                    diff_id  = (node,node_neighbor_item,pos)\n",
    "                    pen_id   = (node,node_neighbor_item,pos)\n",
    "                    diff_var = self.diff[diff_id]\n",
    "                    pen_var  = self.penalty[pen_id]\n",
    "                    \n",
    "                    if pos == 1: # penalty for first position is simple\n",
    "                        self.m.addConstr(pen_var == diff_var,\"penalty_constraint-%s-%s-%s\"%\\\n",
    "                                         (node,node_neighbor_item,pos))\n",
    "                    else:\n",
    "                        pen_prev_id = (node,node_neighbor_item,pos - 1)\n",
    "                        prev_pen_var =  self.penalty[pen_prev_id]\n",
    "                        prev_diff_var = self.diff[pen_prev_id]\n",
    "                        \n",
    "                        self.m.addConstr(diff_var - prev_diff_var >= 1 - self.M * (1 - pen_var),\\\n",
    "                                         name=\"penalty_constraint_1-%s-%s-%s\"%\\\n",
    "                                         (node,node_neighbor_item,pos))\n",
    "                        self.m.addConstr(diff_var - prev_diff_var <= self.M * (pen_var),\\\n",
    "                                         name=\"penalty_constraint_2-%s-%s-%s\"%\\\n",
    "                                         (node,node_neighbor_item,pos))\n",
    "                    \n",
    "                    # add penalty to the objective\n",
    "                    self.objective.append(2 * pen_var)\n",
    "                    \n",
    "        \n",
    "    def train(self,n_threads,time_out):\n",
    "        # Params\n",
    "        self.m.Params.Threads = n_threads\n",
    "        self.m.Params.TimeLimit = time_out*60\n",
    "        #self.m.Params.LogFile =  folder_location + \n",
    "        self.m.Params.LogToConsole = 0\n",
    "        self.m.Params.Degenmoves=0\n",
    "        \n",
    "        # Optimize\n",
    "        self.total_objective = sum([o for o in self.objective])\n",
    "        self.m.setObjective(self.total_objective, GRB.MINIMIZE)\n",
    "        self.m.update()\n",
    "        \n",
    "        self.m.write((self.folder_location + 'pf_mip_formulation_' + self.tree_name + '.lp'))\n",
    "        self.m.optimize()\n",
    "        \n",
    "        # Is feasible?\n",
    "        return self.m.SolCount > 0\n",
    "    \n",
    "    \n",
    "    def get_info(self):\n",
    "        info_all = {}\n",
    "        info_all[\"objective\"] = self.m.ObjVal\n",
    "        info_all[\"bound\"] = self.m.ObjBound\n",
    "        info_all[\"gap\"] = self.m.MIPGap\n",
    "        info_all[\"is_optimal\"] = (self.m.status == GRB.OPTIMAL)\n",
    "        info_all[\"num_nodes\"] = self.m.NodeCount\n",
    "        info_all[\"num_vars\"] = self.m.NumIntVars + self.m.NumBinVars\n",
    "\n",
    "        if self.m.SolCount > 0:\n",
    "            print(\"objective: %0.2f\"%info_all[\"objective\"])\n",
    "            print(\"bound: %0.2f\"%info_all[\"bound\"])\n",
    "            print(\"gap: %0.2f\"%info_all[\"gap\"])\n",
    "\n",
    "        return info_all\n",
    "    \n",
    "    def get_solution(self):\n",
    "        # get the path\n",
    "        all_node_paths = {}\n",
    "        for node,node_edge_from_list in self.node_from_edge_dict.items():\n",
    "            preferred_path = []\n",
    "            for pos_from in range(0,sequence_length):\n",
    "                pos_id = (node,pos_from)\n",
    "                preferred_path.append(int(self.positions[pos_id].X))\n",
    "                \n",
    "            all_node_paths[node] = preferred_path\n",
    "            \n",
    "        # get the differnece and penalty solution\n",
    "        score_dict = {}\n",
    "        overall_score = 0\n",
    "        for node,node_neighbor in self.neighbor_dict.items():\n",
    "            for node_neighbor_item in node_neighbor:\n",
    "                total_score = 0\n",
    "                for pos in range(1,sequence_length - 1): # penalty start from 1st position only\n",
    "                    pen_id = (node,node_neighbor_item,pos)\n",
    "                    diff_id = (node,node_neighbor_item,pos)\n",
    "                    \n",
    "                    total_score = total_score + 2 * int(self.penalty[pen_id].X)\n",
    "                    total_score = total_score + int(self.diff[diff_id].X)\n",
    "                    \n",
    "#                     if node == 'N0' and node_neighbor_item == 'N1':\n",
    "#                         print(\"pen_id\",pen_id)\n",
    "#                         print(int(self.penalty[pen_id].X))\n",
    "#                         print(int(self.diff[diff_id].X))\n",
    "                  \n",
    "                #print(\"total_score between node {} and node-neighbor{} is {}\"\\\n",
    "                                  #.format(node,node_neighbor_item,total_score)) \n",
    "                score_dict[(node,node_neighbor_item)] = total_score\n",
    "                overall_score = overall_score + total_score\n",
    "        print(\"overall_score\",overall_score)\n",
    "        return all_node_paths,score_dict\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3602fc",
   "metadata": {},
   "source": [
    "## RUNNING MIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ca88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST EXAMPLE - 1\n",
    "# folder_location = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/scripts/mip_files/'\n",
    "# nodes = 3\n",
    "# sequence_length = 6 #(start and end pos)\n",
    "# neighbor_dict = dict({1:[2,3]})\n",
    "# extant_list = [2,3]\n",
    "# node_from_edge_dict = dict({\\\n",
    "#                   1:{0:[1,2],1:[2,3,4],2:[3,4],3:[4],4:[5]} ,\\\n",
    "#                   2:{0:[1],1:[2],2:[3],3:[4],4:[5]} ,\\\n",
    "#                   3:{0:[1],1:[2],2:[3],3:[4],4:[5]}})\n",
    "# node_to_edge_dict = dict({\\\n",
    "#                   1:{1:[0],2:[0,1],3:[1,2],4:[1,2,3],5:[4]} ,\\\n",
    "#                   2:{1:[0],2:[1],3:[2],4:[3],5:[4]} ,\\\n",
    "#                   3:{1:[0],2:[1],3:[2],4:[3],5:[4]}\\\n",
    "#                     })\n",
    "# tree_name = 'test_example_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e25380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST EXAMPLE - 2\n",
    "# folder_location = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/scripts/mip_files/'\n",
    "# nodes = 3\n",
    "# sequence_length = 6 #(start and end pos)\n",
    "# neighbor_dict = dict({1:[2,3]})\n",
    "# extant_list = [2,3]\n",
    "# node_from_edge_dict = dict({\\\n",
    "#                   1:{0:[1,2],1:[2,3,4],2:[3,4],3:[4],4:[5]} ,\\\n",
    "#                   2:{0:[1],1:[2],2:[3],3:[4],4:[5]} ,\\\n",
    "#                   3:{0:[1],1:[4],2:[],3:[],4:[5]}})\n",
    "# node_to_edge_dict = dict({\\\n",
    "#                   1:{1:[0],2:[0,1],3:[1,2],4:[1,2,3],5:[4]} ,\\\n",
    "#                   2:{1:[0],2:[1],3:[2],4:[3],5:[4]} ,\\\n",
    "#                   3:{1:[0],2:[],3:[],4:[1],5:[4]}\\\n",
    "#                     })\n",
    "# tree_name = 'test_example_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68ffe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different trees\n",
    "\n",
    "# TEST MIP Models for different trees\n",
    "\n",
    "## sample tree\n",
    "# nwk_file_path = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/sample_tree/grasp_ancestors.nwk'\n",
    "# pogs_file     = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/sample_tree/pogs.json'\n",
    "# tree_name = 'sample_tree'\n",
    "\n",
    "## CYP2U - 165\n",
    "# nwk_file_path       = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_165/grasp_ancestors.nwk'\n",
    "# ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_165/grasp_ancestors.fa\"\n",
    "# pogs_file           = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_165/pogs.json'\n",
    "# tree_name = 'cyp2u_165'\n",
    "# mip_ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_165/mip_grasp_ancestors.fa\"\n",
    "\n",
    "# ## CYP2U - 359\n",
    "# nwk_file_path       = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_359/grasp_ancestors.nwk'\n",
    "# ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_359/grasp_ancestors.fa\"\n",
    "# pogs_file           = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_359/pogs.json'\n",
    "# tree_name = 'cyp2u_359'\n",
    "\n",
    "# ## CYP2U - 595\n",
    "nwk_file_path       = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_595/grasp_ancestors.nwk'\n",
    "ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_595/grasp_ancestors.fa\"\n",
    "pogs_file           = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_595/pogs.json'\n",
    "mip_ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/CYP2U_595/\\\n",
    "mip_grasp_ancestors.fa\"\n",
    "tree_name = 'cyp2u_595'\n",
    "\n",
    "# ## DHAD - 585\n",
    "# nwk_file_path       = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/DHAD_585/grasp_ancestors.nwk'\n",
    "# ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/DHAD_585/grasp_ancestors.fa\"\n",
    "# pogs_file           = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/DHAD_585/pogs.json'\n",
    "# tree_name = 'dhad_585'\n",
    "\n",
    "# ## DHAD - 1612\n",
    "# nwk_file_path       = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/DHAD_1612/grasp_ancestors.nwk'\n",
    "# ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/DHAD_1612/grasp_ancestors.fa\"\n",
    "# pogs_file           = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/DHAD_1612/pogs.json'\n",
    "# tree_name = 'dhad_1612' \n",
    "\n",
    "\n",
    "# ## KARI - 1176\n",
    "# nwk_file_path       = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/KARI_1176/grasp_ancestors.nwk'\n",
    "# ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/KARI_1176/grasp_ancestors.fa\"\n",
    "# pogs_file           = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/KARI_1176/pogs.json'\n",
    "# tree_name = 'kari_1176' \n",
    "\n",
    "# ## GO - 399\n",
    "# nwk_file_path       = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/GDH-GOx_399/grasp_ancestors.nwk'\n",
    "# ancestor_fasta_file = \"/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/GDH-GOx_399/grasp_ancestors.fa\"\n",
    "# pogs_file           = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/data/GDH-GOx_399/pogs.json'\n",
    "# tree_name = 'go_399' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753e38c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL NODES:: 1189\n",
      "TOTAL POSITIONS: 664\n"
     ]
    }
   ],
   "source": [
    "##### GET THE INPUT FOR MIP READY #####\n",
    "\n",
    "folder_location = '/Users/sanjanatule/Documents/uq/Projects/PreferredPath/scripts/mip_files/'\n",
    "TreePogs = Pogs(pogs_file,nwk_file_path)\n",
    "node_from_edge_dict,node_from_reverse_edge_dict,sequence_length,extant_list,node_pogs_cnt,\\\n",
    "                                                        node_pogs = TreePogs.create_node_info_dict()\n",
    "neighbor_dict = TreePogs.create_neighbor_object()\n",
    "nodes = len(node_from_edge_dict)\n",
    "node_type_dict = TreePogs.node_type_info()\n",
    "print(\"TOTAL NODES::\",nodes)\n",
    "print(\"TOTAL POSITIONS:\",sequence_length)\n",
    "#print(\"EXTANT LIST:\",extant_list)\n",
    "# print(\"NEIGHBOR DICT:\",neighbor_dict)\n",
    "# print('NODE TYPE DICT:',node_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc6e2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 1662600192.20453\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-08-19\n",
      "Set parameter Threads to value 1\n",
      "Set parameter TimeLimit to value 3600\n",
      "is_sat True\n",
      "-----------------------------\n",
      "Total time = 211.36[m]\n",
      "objective: 5166.00\n",
      "bound: 5166.00\n",
      "gap: 0.00\n",
      "info {'objective': 5166.0, 'bound': 5166.0, 'gap': 0.0, 'is_optimal': True, 'num_nodes': 1.0, 'num_vars': 4787626, 'total_time': 211.35943603515625, 'is_sat': True}\n",
      "overall_score 5166\n"
     ]
    }
   ],
   "source": [
    "#### RUN OPTIMISATION ####\n",
    "\n",
    "start = time.time()\n",
    "print(\"Start Time:\",start)\n",
    "n_threads = 1\n",
    "time_out = 60\n",
    "# initialise the class\n",
    "PyTree = PhyloTree(nodes,sequence_length,neighbor_dict,node_from_edge_dict,folder_location\\\n",
    "                   ,extant_list,tree_name,node_type_dict,node_from_reverse_edge_dict)\n",
    "\n",
    "PyTree.add_pos_var_constraints()\n",
    "PyTree.add_edges_var_constraints()\n",
    "PyTree.add_pos_constraints_extants()\n",
    "PyTree.add_constraints_ancestors()\n",
    "PyTree.penalty_constraints()\n",
    "\n",
    "is_sat = PyTree.train(n_threads, time_out)\n",
    "print(\"is_sat\",is_sat)\n",
    "total_time = ((time.time()-start))\n",
    "print(\"-----------------------------\")\n",
    "print(\"Total time = %0.2f[m]\"%total_time)\n",
    "info = PyTree.get_info()\n",
    "info[\"total_time\"] = total_time\n",
    "info[\"is_sat\"] = is_sat\n",
    "print(\"info\",info)\n",
    "\n",
    "if is_sat:\n",
    "    all_node_paths,score_dict = PyTree.get_solution()\n",
    "    #print(\"all_node_paths\",all_node_paths)\n",
    "else:\n",
    "    print(\"Did not find any satisfactory solution to the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e313ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output file to FASTA file\n",
    "with open(mip_ancestor_fasta_file,mode='w') as fout:\n",
    "    for node_name,sequence in all_node_paths.items():\n",
    "        fout.write('>' + str(node_name) + '\\n')\n",
    "        sequence_str = ''.join([str(s) for s in sequence])\n",
    "        fout.write(str(sequence_str) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc24d3",
   "metadata": {},
   "source": [
    "## CHECKING THE MIP SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "187b915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' functions for use in checking solution '''\n",
    "\n",
    "''' get the sequence string after removing commas and start/end node'''\n",
    "def get_sequence_string(preferred_path):\n",
    "    pf_str = ''\n",
    "    for p in preferred_path:\n",
    "        pf_str = pf_str + str(p)\n",
    "\n",
    "    # remove first and last path\n",
    "    pf_str = pf_str[1:-1]\n",
    "    return pf_str\n",
    "\n",
    "''' verify the score given by mip '''\n",
    "def sequence_distance_score(str1,str2):\n",
    "    dis = 0\n",
    "    prev_dis = 0\n",
    "    \n",
    "    for i in range(0,len(str1)):\n",
    "        if str1[i] != str2[i]:  # not matching\n",
    "            if prev_dis == 0:   # previous unmatched\n",
    "                dis += 3\n",
    "                prev_dis = 1\n",
    "            else:\n",
    "                dis += 1\n",
    "        else:\n",
    "            prev_dis = 0\n",
    "    return dis\n",
    "\n",
    "''' Check if path is valid path and not broken '''\n",
    "def next_one(from_pos,path,seq_length):\n",
    "    if from_pos == seq_length - 1:  # end pos\n",
    "        return from_pos\n",
    "    for p_ind in range(from_pos + 1,seq_length):\n",
    "        if path[p_ind] == 1:\n",
    "            return p_ind\n",
    "        \n",
    "def check_path_complete(pog_mat,path,seq_length):\n",
    "    valid = 0\n",
    "    # first position\n",
    "    from_p = 0\n",
    "    to_p = next_one(from_p,path,seq_length)\n",
    "    \n",
    "    while(1):\n",
    "        if pog_mat[from_p][to_p] == 1:\n",
    "            from_p = to_p\n",
    "            to_p   = next_one(from_p,path,seq_length) # next position with 1\n",
    "            #print('to_p',to_p)\n",
    "            \n",
    "            if to_p == seq_length - 1: # end position\n",
    "                valid = 1\n",
    "                break\n",
    "        else:\n",
    "            valid = 0\n",
    "            break\n",
    "    return valid\n",
    "\n",
    "# test\n",
    "# pog_mat = np.array([(0,0,1),(0,0,0),(0,0,0)])\n",
    "# path = [1,0,1]\n",
    "# seq_length = 3\n",
    "# check_path_complete(pog_mat,path,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b63901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking node:: N0\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N3\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N21\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N29\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N36\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N39\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N47\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N51\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N124\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N125\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N134\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N135\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N137\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N139\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N145\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N161\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N163\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N352\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N353\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N354\n",
      "OK: path is different for ancestor.\n",
      "checking node:: N580\n",
      "OK: path is different for ancestor.\n",
      "Total nodes changed 21\n"
     ]
    }
   ],
   "source": [
    "''' 1 - check whether path is complete and fixed path are not changed '''\n",
    "# 1 -- check output from mip \n",
    "def check_mip_output_node_changes(grasp_fasta_file,all_node_paths,extant_list,node_pogs,node_pogs_cnt):\n",
    "    \n",
    "    sequences_info = FastaFile(grasp_fasta_file)\n",
    "    total_node_change = 0\n",
    "\n",
    "    for node_name,preferred_path in all_node_paths.items(): # mip path\n",
    "        grasp_output_seq = sequences_info.fetch(node_name)\n",
    "\n",
    "        # convert into 1/0\n",
    "        grasp_output_seq =  re.sub('[a-zA-Z]', '1', grasp_output_seq)\n",
    "        grasp_output_seq = grasp_output_seq.replace('-','0')\n",
    "        #print('grasp_output_seq',grasp_output_seq)\n",
    "\n",
    "        # compare with mip output\n",
    "        pf_str = ''\n",
    "        for p in preferred_path:\n",
    "            pf_str = pf_str + str(p)\n",
    "\n",
    "        # remove first and last path\n",
    "        pf_str = pf_str[1:-1]\n",
    "\n",
    "        #print(\"preferred_path\",pf_str)\n",
    "        if grasp_output_seq != pf_str:\n",
    "            print(\"checking node::\",node_name)\n",
    "            total_node_change += 1\n",
    "\n",
    "            if node_name in extant_list:\n",
    "                print(\"ERROR: path is different for an extant.Should not change.\")\n",
    "            else:\n",
    "                if node_pogs_cnt[node_name] == 1:\n",
    "                    print(\"ERROR: path is different for ancestor.Should not change.\")\n",
    "                else:\n",
    "                    print(\"OK: path is different for ancestor.\")\n",
    "\n",
    "\n",
    "        # check if the path is complete\n",
    "        pog_mat = node_pogs[node_name]\n",
    "        if check_path_complete(pog_mat,preferred_path,sequence_length) == 0:\n",
    "            print(\"Path is not complete. Incorrect results.\")\n",
    "\n",
    "    print(\"Total nodes changed\",total_node_change)\n",
    "\n",
    "check_mip_output_node_changes(ancestor_fasta_file,all_node_paths,extant_list,node_pogs,node_pogs_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60c8f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 2 - compare/check the score function between heuristic and mip method '''\n",
    "### 2 - check score\n",
    "def check_score(score_dict,neighbor_dict):\n",
    "    # compare score with hueristics solution\n",
    "    for node,node_neighbor_list in neighbor_dict.items():\n",
    "        node_sequence = get_sequence_string(all_node_paths[node])\n",
    "        for nn in node_neighbor_list:\n",
    "            nn_sequence = get_sequence_string(all_node_paths[nn])\n",
    "            # calculate score between the nodes\n",
    "            diff_score = sequence_distance_score(node_sequence,nn_sequence)\n",
    "            # compare with mip score\n",
    "            mip_score = score_dict[(node,nn)]\n",
    "            if diff_score != mip_score:\n",
    "                print('node',node)\n",
    "                print(\"node neighbor\",nn)\n",
    "                print(\"diff_score\",diff_score)\n",
    "                print(\"mip_score\",mip_score)\n",
    "                print(\"ERROR: Score is different\")\n",
    "                print(\"node sequence\",node_sequence)\n",
    "                print(\"nn sequence\",nn_sequence)\n",
    "check_score(score_dict,neighbor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e3db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
