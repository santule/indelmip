{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8950125e",
   "metadata": {},
   "source": [
    "## MIP Program for choosing preferred path for ancestor nodes.\n",
    "1. Program - Gurobi Solver.\n",
    "2. Date - 24 April 2023.\n",
    "3. Formulate the problem using extant sequences and the phylogenetic tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "d2fdbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import gurobipy as gp\n",
    "from gurobipy import abs_,quicksum\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from ete3 import Tree\n",
    "import numpy as np\n",
    "from pysam import FastaFile,FastxFile\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026583a",
   "metadata": {},
   "source": [
    "## 1 - INPUT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "b681de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to convert fasta file into adj matrix\n",
    "\n",
    "\n",
    "# pytorch dataset to save the extant data\n",
    "class AjMat_Dataset(Dataset):\n",
    "    def __init__(self,adj_mat,seq_name,seq_fwd_pog,seq_rvs_pog,node_type,seq_binary):\n",
    "        self.adj_mat = adj_mat\n",
    "        self.seq_name = seq_name\n",
    "        self.seq_fwd_pog = seq_fwd_pog\n",
    "        self.seq_rvs_pog = seq_rvs_pog\n",
    "        self.node_type = node_type\n",
    "        self.seq_binary = seq_binary\n",
    "        \n",
    "    def __len__(self):      \n",
    "        return len(self.adj_mat)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.adj_mat[idx],self.seq_name[idx],self.seq_fwd_pog[idx],\\\n",
    "               self.seq_rvs_pog[idx],self.node_type[idx],self.seq_binary[idx]\n",
    "\n",
    "    \n",
    "class IndelsInfo:\n",
    "    def __init__(self,AjMat_Dataset,fasta_file,nwk_file_path,sequence_length):\n",
    "        \n",
    "        self.AjMat_Dataset = AjMat_Dataset\n",
    "        self.input_file = fasta_file\n",
    "        self.nwk_file_path = nwk_file_path\n",
    "        self.ancestor_list = []\n",
    "        self.tree_neighbor_dict = defaultdict(list)\n",
    "        self.ancestor_info = []\n",
    "        self.sequence_length = sequence_length\n",
    "        self.Extant_AdjMat_dataset = AjMat_Dataset\n",
    "        \n",
    "    \n",
    "    # create node types for each position for each sequences\n",
    "    def create_node_type(self, seq_fwd_pog,seq_rvs_pog,sequence_length,seq_name):\n",
    "        node_type_dict = defaultdict(list)\n",
    "        node_type_dict[(seq_name,'start')] = [0]\n",
    "        node_type_dict[(seq_name,'end')] = [self.sequence_length - 1]\n",
    "\n",
    "        for n in range(1,self.sequence_length - 1):\n",
    "            if n in seq_fwd_pog.keys() and n in seq_rvs_pog.keys(): #if node has forward and backward\n",
    "                node_type_dict[(seq_name,'fwd_back_pos')] += [n]\n",
    "            elif n in seq_fwd_pog.keys() and n not in seq_rvs_pog.keys():\n",
    "                node_type_dict[(seq_name,'fwd_pos')] += [n]\n",
    "            elif n not in seq_fwd_pog.keys() and n in seq_rvs_pog.keys():\n",
    "                node_type_dict[(seq_name,'back_pos')] += [n]\n",
    "            else:\n",
    "                node_type_dict[(seq_name,'dead_pos')] += [n]\n",
    "        return node_type_dict\n",
    "\n",
    "    # function to find next position that is filled\n",
    "    def next_pos(str1,curr_pos,seq_len):\n",
    "        start_pos = curr_pos + 1\n",
    "\n",
    "        while(start_pos < len(str1)):\n",
    "            if str1[start_pos] != '-':\n",
    "                return start_pos\n",
    "            else:\n",
    "                start_pos = start_pos + 1\n",
    "        return seq_len\n",
    "\n",
    "    # function to convert a sequence to adj matrix\n",
    "    def convert_to_adj_mat(self,seq_str):\n",
    "        seq_len = len(seq_str)\n",
    "        aj_mat_array = np.zeros((seq_len,seq_len))\n",
    "\n",
    "        next_filled = []\n",
    "        ind = 0\n",
    "\n",
    "        while(ind < seq_len - 1):\n",
    "            if seq_str[ind] != '-':\n",
    "                curr_ind = ind\n",
    "                ind = next_pos(seq_str,curr_ind,seq_len - 1) # find the next filled position\n",
    "                next_filled.append((curr_ind,ind))\n",
    "                aj_mat_array[curr_ind,ind] = 1\n",
    "            else:\n",
    "                ind = ind + 1\n",
    "        return aj_mat_array\n",
    "\n",
    "\n",
    "    # convert adj matrix into pog dictionary\n",
    "    def create_extant_pog(self,adj_mat_t):\n",
    "        x_summ = np.column_stack(np.where(adj_mat_t))\n",
    "        seq_fwd_pog_dict = dict(zip(x_summ[:,0], x_summ[:,1]))\n",
    "        seq_rvs_pog_dict = dict(zip(x_summ[:,1], x_summ[:,0]))\n",
    "        return seq_fwd_pog_dict,seq_rvs_pog_dict\n",
    "    \n",
    "    # 1 - convert fasta file to adj matrix, pog, node type, seq binary into pytorch dataset\n",
    "    def get_extant_data(self):\n",
    "        adj_mat_list      = []\n",
    "        seq_name_list     = []\n",
    "        seq_fwd_pog_list  = []\n",
    "        node_type_list    = []\n",
    "        seq_rev_pog_list  = []\n",
    "        seq_binary_list   = []\n",
    "\n",
    "        with FastxFile(self.input_file) as fh:\n",
    "            for entry in fh: \n",
    "                # add start and end string to the sequence\n",
    "                seq_name = entry.name\n",
    "                new_sequence = 'x' + entry.sequence + 'x'\n",
    "\n",
    "                # convert to adj matrix\n",
    "                seq_adj_mat  = self.convert_to_adj_mat(new_sequence)\n",
    "\n",
    "                # binarise sequences\n",
    "                seq_binary   = ''.join(sum(seq_adj_mat).astype(int).astype(str))\n",
    "                # make start pos as 1 for start node\n",
    "                seq_binary = '1' + seq_binary[1:]\n",
    "\n",
    "                # convert to pog structure\n",
    "                seq_fwd_pog,seq_rvs_pog = self.create_extant_pog(seq_adj_mat)\n",
    "\n",
    "                # create node type dict\n",
    "                node_type = self.create_node_type(seq_fwd_pog,seq_rvs_pog,new_sequence,seq_name)\n",
    "\n",
    "                # add to the list\n",
    "                #adj_mat_t = torch.from_numpy(seq_adj_mat)\n",
    "                adj_mat_list.append(seq_adj_mat)\n",
    "                seq_name_list.append(seq_name)            \n",
    "                seq_fwd_pog_list.append(seq_fwd_pog)\n",
    "                seq_rev_pog_list.append(seq_rvs_pog)\n",
    "                node_type_list.append(node_type)\n",
    "                seq_binary_list.append(seq_binary)\n",
    "\n",
    "        # save it into pytorch dataset\n",
    "        self.Extant_AdjMat_dataset = self.AjMat_Dataset(adj_mat_list, seq_name_list, seq_fwd_pog_list,\n",
    "                                              seq_rev_pog_list, node_type_list,seq_binary_list)\n",
    "\n",
    "        return self.Extant_AdjMat_dataset\n",
    "\n",
    "    # 2 - create neighbour dict using the tree file\n",
    "    def get_tree_data(self):\n",
    "\n",
    "        ''' create neighbor dict '''\n",
    "        tree_file = open(self.nwk_file_path,\"r\")\n",
    "        my_tree = tree_file.read() + \";\"\n",
    "        tree = Tree(my_tree, format=1)\n",
    "\n",
    "        # add node names to the internal branches\n",
    "        edge = 0\n",
    "        for n in tree.traverse():\n",
    "            if not n.is_leaf():\n",
    "                n.name = \"NODE_%d\" %edge\n",
    "                edge += 1\n",
    "                self.ancestor_list.append(n.name)\n",
    "\n",
    "        # create neighbourhood object\n",
    "        for n in tree.traverse():\n",
    "            if n.is_leaf() == False:    \n",
    "                for c in n.children:\n",
    "                    self.tree_neighbor_dict[n.name] += [c.name]\n",
    "\n",
    "        return self.tree_neighbor_dict\n",
    "    \n",
    "    # 3 - ancestor data - all ancestors, aggregated pog, aggregated adj mat\n",
    "    def get_ancestor_data(self):\n",
    "\n",
    "        # all ancestors name\n",
    "        ancestor_branchpoints = self.ancestor_list\n",
    "\n",
    "        ancestor_fwd_pog = defaultdict(list)\n",
    "        ancestor_rvs_pog = defaultdict(list)\n",
    "\n",
    "        # ancestor adj mat\n",
    "        ancestor_adj_mat = np.where(sum(self.Extant_AdjMat_dataset[:][0]))\n",
    "\n",
    "        # ancestor foward and backward pog\n",
    "        row_col_sum = np.column_stack(np.where(sum(self.Extant_AdjMat_dataset[:][0])))\n",
    "        for r in row_col_sum:\n",
    "            pos = r[0]\n",
    "            next_pos = r[1]\n",
    "            ancestor_fwd_pog[pos] += [next_pos] \n",
    "            ancestor_rvs_pog[next_pos] += [pos]\n",
    "\n",
    "        # create node type dict\n",
    "        ancestor_node_type = create_node_type(ancestor_fwd_pog,ancestor_rvs_pog,sample_sequence,'ANCESTOR')\n",
    "        self.ancestor_info = [ancestor_branchpoints,ancestor_fwd_pog,ancestor_rvs_pog,ancestor_node_type]\n",
    "        return self.ancestor_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "da773f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files - .nwk file, extant sequence file, folder location\n",
    "\n",
    "nwk_file_path        = '/Users/sanjanatule/Documents/uq/Projects/MIPIndel/data/st1/input_tree.nwk'\n",
    "extant_sequence_file = '/Users/sanjanatule/Documents/uq/Projects/MIPIndel/data/st1/input_extants.fasta'\n",
    "folder_location      = '/Users/sanjanatule/Documents/uq/Projects/MIPIndel/scripts/mip_files/'\n",
    "sequence_length = 15\n",
    "\n",
    "# instantiate class\n",
    "MIPIndel      = IndelsInfo(AjMat_Dataset,extant_sequence_file,nwk_file_path,sequence_length)\n",
    "extant_data   = MIPIndel.get_extant_data() # pog, adj matrix, binary, node type\n",
    "neighbor_dict = MIPIndel.get_tree_data() # neighbor info\n",
    "ancestor_data = MIPIndel.get_ancestor_data() # ancestor pog, node type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "843b9ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'A3', {0: 1, 1: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15}, {1: 0, 3: 1, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14}, defaultdict(<class 'list'>, {('A3', 'start'): [0], ('A3', 'end'): [14], ('A3', 'fwd_back_pos'): [1, 3, 4, 5, 6, 7, 10, 11, 12, 13], ('A3', 'dead_pos'): [2, 8, 9]}), '1101111100111111')\n"
     ]
    }
   ],
   "source": [
    "print(extant_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "5a6990cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NODE_0', 'NODE_1', 'NODE_2', 'NODE_3', 'NODE_4', 'NODE_5', 'NODE_6', 'NODE_7', 'NODE_8', 'NODE_9', 'NODE_10', 'NODE_11', 'NODE_12', 'NODE_13', 'NODE_14', 'NODE_15', 'NODE_16', 'NODE_17', 'NODE_18'], defaultdict(<class 'list'>, {0: [1, 2, 4], 1: [3], 2: [3], 3: [4], 4: [5], 5: [6], 6: [7], 7: [8, 10], 8: [9, 10], 9: [10], 10: [11, 12, 13], 11: [12], 12: [13, 14], 13: [14], 14: [15]}), defaultdict(<class 'list'>, {1: [0], 2: [0], 4: [0, 3], 3: [1, 2], 5: [4], 6: [5], 7: [6], 8: [7], 10: [7, 8, 9], 9: [8], 11: [10], 12: [10, 11], 13: [10, 12], 14: [12, 13], 15: [14]}), defaultdict(<class 'list'>, {('ANCESTOR', 'start'): [0], ('ANCESTOR', 'end'): [15], ('ANCESTOR', 'fwd_back_pos'): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]})]\n"
     ]
    }
   ],
   "source": [
    "print(ancestor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "cb07f868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'NODE_0': ['NODE_1', 'NODE_2'], 'NODE_1': ['NODE_3', 'NODE_4'], 'NODE_2': ['NODE_5', 'NODE_6'], 'NODE_3': ['NODE_7', 'NODE_8'], 'NODE_4': ['A5', 'NODE_9'], 'NODE_5': ['NODE_10', 'NODE_11'], 'NODE_6': ['A2', 'A6'], 'NODE_7': ['NODE_12', 'A4'], 'NODE_8': ['A20', 'A8'], 'NODE_9': ['NODE_13', 'A17'], 'NODE_10': ['A10', 'NODE_14'], 'NODE_11': ['NODE_15', 'NODE_16'], 'NODE_12': ['A3', 'A9'], 'NODE_13': ['A19', 'A1'], 'NODE_14': ['A7', 'A16'], 'NODE_15': ['A18', 'A13'], 'NODE_16': ['A15', 'NODE_17'], 'NODE_17': ['A14', 'NODE_18'], 'NODE_18': ['A11', 'A12']})\n"
     ]
    }
   ],
   "source": [
    "print(neighbor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4364f96",
   "metadata": {},
   "source": [
    "## 2 - MIP FORMULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1385b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhyloTreeMIP:\n",
    "    def __init__(self,extant_data,ancestor_data,tree_name,neighbor_dict):\n",
    "\n",
    "        # Define the configuration  and decision variables for the tree\n",
    "        self.extant_data = extant_data\n",
    "        self.ancestor_data = ancestor_data\n",
    "        self.tree_name = tree_name\n",
    "        self.sequence_length = len(self.extant_data[0][5])\n",
    "        self.neighbor_dict = neighbor_dict\n",
    "        self.objective = []\n",
    "        \n",
    "        \n",
    "        # MIP data structures\n",
    "        self.edges = {}\n",
    "        self.positions = {}\n",
    "        self.penalty = {}\n",
    "        self.diff = {}\n",
    "        self.objective = []\n",
    "        self.M = 999\n",
    "\n",
    "        # 2 - create a new model\n",
    "        self.m = gp.Model(\"PreferredPathSolve\")\n",
    "        \n",
    "    \n",
    "    def add_pos_constraints_extants(self):\n",
    "        ''' function to add constraints for positions in extants to fix them '''\n",
    "    \n",
    "        \n",
    "        for extant_info in self.extant_data:\n",
    "            sequence_binary = extant_info[5]\n",
    "            sequence_name   = extant_info[1]\n",
    "            # V - create variable for each position for each extant sequence\n",
    "            for pos_idx in range(0,len(sequence_binary)):\n",
    "                pos_id = (sequence_name,pos_idx)\n",
    "                pos = self.m.addVar(vtype=GRB.BINARY, name=\"p-%s-%s\"%pos_id)\n",
    "                self.positions[pos_id] = pos\n",
    "                \n",
    "                # C - fix the extant positions as per binary sequence\n",
    "                self.m.addConstr(self.positions[pos_id] == int(sequence_binary[pos_idx]),\\\n",
    "                                     name=\"extant_position_constraint-%s-%s\"%pos_id)\n",
    "                \n",
    "    def add_pos_constraints_ancestors(self):\n",
    "        ''' function to add constraints for positions in ancestors  '''\n",
    "        \n",
    "        ancestor_list = self.ancestor_data[0]\n",
    "        \n",
    "        # V - create variable for each position for each ancestor sequence\n",
    "        for ancestor in ancestor_list:\n",
    "            for pos_idx in range(0,self.sequence_length):\n",
    "                pos_id = (ancestor,pos_idx)\n",
    "                pos = self.m.addVar(vtype=GRB.BINARY, name=\"p-%s-%s\"%pos_id)\n",
    "                self.positions[pos_id] = pos\n",
    "                \n",
    "            # C - start pos is always 1\n",
    "            pos_id = (ancestor,0)\n",
    "            pos = self.m.addVar(vtype=GRB.BINARY, name=\"p-%s-%s\"%pos_id)\n",
    "            self.positions[pos_id] = pos\n",
    "            \n",
    "            # C - end pos is always 1\n",
    "            pos_id = (ancestor,self.sequence_length-1)\n",
    "            pos = self.m.addVar(vtype=GRB.BINARY, name=\"p-%s-%s\"%pos_id)\n",
    "            self.positions[pos_id] = pos\n",
    "                \n",
    "    def add_edge_constraints_ancestors(self):\n",
    "        ''' function to add constraints for edges in ancestors  '''\n",
    "        \n",
    "        ancestor_list = ancestor_data[0]\n",
    "        ancestor_node_type = ancestor_data[3]\n",
    "        ancestor_fwd_edges = ancestor_data[1]\n",
    "        ancestor_bkwd_edges = ancestor_data[2]\n",
    "        \n",
    "        # constraint for each ancestor\n",
    "        for ancestor in ancestor_list:\n",
    "            \n",
    "            # START NODES    \n",
    "            for fwd_back_pos in ancestor_node_type.get(('ANCESTOR','start')):\n",
    "                \n",
    "                all_edges_from_pos = []\n",
    "                for pos_to in ancestor_fwd_edges[fwd_back_pos]:\n",
    "                    edge_id = (ancestor,fwd_back_pos,pos_to)\n",
    "                    # V - var for each edge from start node\n",
    "                    e = self.m.addVar(vtype=GRB.BINARY, name='e-%s-%s-%s'%edge_id)\n",
    "                    self.edges[edge_id] = e\n",
    "                    all_edges_from_pos.append(e)\n",
    "                    \n",
    "                # C - only 1 edge can be used\n",
    "                pos_id = (ancestor,fwd_back_pos)\n",
    "                self.m.addConstr(quicksum(all_edges_from_pos) <= 1,name=\\\n",
    "                                          \"ancestor_start_edge_constraint-%s-%s\"%pos_id)\n",
    "                # C - sum(edges) = position\n",
    "                self.m.addConstr(quicksum(all_edges_from_pos) == self.positions[pos_id],\\\n",
    "                                            name = \"ancestor_edge_node_recon_constraint-%s-%s\"%pos_id)\n",
    "                \n",
    "            \n",
    "            # END NODES\n",
    "            for fwd_back_pos in ancestor_node_type.get(('ANCESTOR','end')):\n",
    "                \n",
    "                all_edges_to_pos = []\n",
    "                for pos_from in ancestor_bkwd_edges[fwd_back_pos]:\n",
    "                    edge_id = (ancestor,pos_from,fwd_back_pos)\n",
    "                    # V - var for each edge to end node\n",
    "                    e = self.m.addVar(vtype=GRB.BINARY, name='e-%s-%s-%s'%edge_id)\n",
    "                    self.edges[edge_id] = e\n",
    "                    all_edges_to_pos.append(e)\n",
    "                    \n",
    "                # C - only 1 edge can be used\n",
    "                pos_id = (ancestor,fwd_back_pos)\n",
    "                self.m.addConstr(quicksum(all_edges_to_pos) <= 1,name=\\\n",
    "                                          \"ancestor_end_edge_constraint-%s-%s\"%pos_id)\n",
    "                # C - sum(edges) = position\n",
    "                self.m.addConstr(quicksum(all_edges_to_pos) == self.positions[pos_id],\\\n",
    "                                            name = \"ancestor_edge_node_recon_constraint-%s-%s\"%pos_id)\n",
    "                \n",
    "                \n",
    "            # DEAD NODES \n",
    "            if ancestor_node_type.get(('ANCESTOR','dead_pos')) :\n",
    "                for fwd_back_pos in ancestor_node_type.get(('ANCESTOR','dead_pos')):\n",
    "                    pos_id = (ancestor,fwd_back_pos)\n",
    "                    # C - constraint for dead pos to 0 as they cannot find complete path\n",
    "                    self.m.addConstr(self.positions[pos_id] == 0,\\\n",
    "                                                name = \"ancestor_dead_pos-%s-%s\"%pos_id)\n",
    "                    \n",
    "            # FULLY CONNECTED NODES\n",
    "            for fwd_back_pos in ancestor_node_type.get(('ANCESTOR','fwd_back_pos')):\n",
    "                \n",
    "                \n",
    "                all_edges_from_pos = []\n",
    "                for pos_to in ancestor_fwd_edges[fwd_back_pos]:\n",
    "                    edge_id = (ancestor,fwd_back_pos,pos_to)\n",
    "                    # V - var for each edge going from the node\n",
    "                    e = self.m.addVar(vtype=GRB.BINARY, name='e-%s-%s-%s'%edge_id)\n",
    "                    self.edges[edge_id] = e\n",
    "                    all_edges_from_pos.append(e)\n",
    "                    \n",
    "                # C - only 1 edge can be used\n",
    "                pos_id = (ancestor,fwd_back_pos)\n",
    "                self.m.addConstr(quicksum(all_edges_from_pos) <= 1,name=\\\n",
    "                                          \"ancestor_edge_constraint-%s-%s\"%pos_id)\n",
    "                \n",
    "                # C - sum(edges going in) = sum(edges going out) for each node\n",
    "                edges_coming_in_list = []\n",
    "                for edges_coming_in_item in ancestor_bkwd_edges[fwd_back_pos]:\n",
    "                    edge_to_id = (ancestor,edges_coming_in_item,fwd_back_pos)\n",
    "                    edges_coming_in_list.append(self.edges[edge_to_id])\n",
    "                \n",
    "                self.m.addConstr(quicksum(edges_coming_in_list) == quicksum(all_edges_from_pos),\\\n",
    "                                                 name=\"ancestor_edge_recon_constraint-%s-%s\"%pos_id)\n",
    "                # C - sum(edges) = position\n",
    "                self.m.addConstr(quicksum(all_edges_from_pos) == self.positions[pos_id],\\\n",
    "                                            name=\"ancestor_edge_node_recon_constraint1-%s-%s\"%pos_id)\n",
    "                # C - sum(edges) = position       \n",
    "                self.m.addConstr(quicksum(edges_coming_in_list) == self.positions[pos_id],\\\n",
    "                                            name=\"ancestor_edge_node_recon_constraint2-%s-%s\"%pos_id)\n",
    "                \n",
    "            \n",
    "                \n",
    "    # penalty constraint\n",
    "    def add_penalty_constraint(self):\n",
    "        ''' function to add penalty constraints for whole tree  '''\n",
    "        \n",
    "        # difference constraints\n",
    "        for node,node_neighbor in self.neighbor_dict.items():\n",
    "            for node_neighbor_item in node_neighbor:\n",
    "                for pos in range(1,self.sequence_length - 1): # penalty start from 1st position only\n",
    "                    \n",
    "                    # V - penalty variables for node to node for each position\n",
    "                    pen_id = (node,node_neighbor_item,pos)\n",
    "                    pen = self.m.addVar(vtype=GRB.BINARY, name='pe-%s-%s-%s'%pen_id)\n",
    "                    self.penalty[pen_id] = pen\n",
    "\n",
    "                    # V - add position difference variable\n",
    "                    node_pos_var = self.positions[(node,pos)]\n",
    "                    node_neighbor_pos_var = self.positions[(node_neighbor_item,pos)]\n",
    "                    diff_id = (node,node_neighbor_item,pos)\n",
    "                    diff_pos = self.m.addVar(vtype=GRB.BINARY, name='d-%s-%s-%s'%diff_id)\n",
    "                    self.diff[diff_id] = diff_pos\n",
    "\n",
    "                    # C - abs difference constraint\n",
    "                    self.m.addConstr( diff_pos <= node_pos_var + node_neighbor_pos_var,name=\\\n",
    "                                     \"diff_constraint_1-%s-%s-%s\"%(node,node_neighbor_item,pos))\n",
    "                    self.m.addConstr( diff_pos >= node_pos_var - node_neighbor_pos_var,name=\\\n",
    "                                     \"diff_constraint_2-%s-%s-%s\"%(node,node_neighbor_item,pos))\n",
    "                    self.m.addConstr( diff_pos >= node_neighbor_pos_var - node_pos_var,name=\\\n",
    "                                     \"diff_constraint_3-%s-%s-%s\"%(node,node_neighbor_item,pos))\n",
    "                    self.m.addConstr( diff_pos <= 2 - node_neighbor_pos_var - node_pos_var,name=\\\n",
    "                                     \"diff_constraint_4-%s-%s-%s\"%(node,node_neighbor_item,pos))\n",
    "                    # O - add objective\n",
    "                    self.objective.append(diff_pos)\n",
    "                    \n",
    "        # gap penalty constraints\n",
    "        for node,node_neighbor in self.neighbor_dict.items():\n",
    "            for node_neighbor_item in node_neighbor:\n",
    "                for pos in range(1,self.sequence_length - 1):  # no penalty for start and end\n",
    "                    diff_id  = (node,node_neighbor_item,pos)\n",
    "                    pen_id   = (node,node_neighbor_item,pos)\n",
    "                    diff_var = self.diff[diff_id]\n",
    "                    pen_var  = self.penalty[pen_id]\n",
    "                    \n",
    "                    if pos == 1: # penalty for first position is simple\n",
    "                        self.m.addConstr(pen_var == diff_var,\"penalty_constraint-%s-%s-%s\"%\\\n",
    "                                         (node,node_neighbor_item,pos))\n",
    "                    else:\n",
    "                        pen_prev_id = (node,node_neighbor_item,pos - 1)\n",
    "                        prev_pen_var =  self.penalty[pen_prev_id]\n",
    "                        prev_diff_var = self.diff[pen_prev_id]\n",
    "                        \n",
    "                        # C - gap opening penalty\n",
    "                        self.m.addConstr(diff_var - prev_diff_var >= 1 - self.M * (1 - pen_var),\\\n",
    "                                         name=\"penalty_constraint_1-%s-%s-%s\"%\\\n",
    "                                         (node,node_neighbor_item,pos))\n",
    "                        self.m.addConstr(diff_var - prev_diff_var <= self.M * (pen_var),\\\n",
    "                                         name=\"penalty_constraint_2-%s-%s-%s\"%\\\n",
    "                                         (node,node_neighbor_item,pos))\n",
    "                    \n",
    "                    # O - add penalty to the objective\n",
    "                    self.objective.append(2 * pen_var)\n",
    "                    \n",
    "        \n",
    "        \n",
    "    def train(self,n_threads,time_out):\n",
    "        # Params\n",
    "        self.m.Params.Threads = n_threads\n",
    "        self.m.Params.TimeLimit = time_out*60\n",
    "        self.m.Params.LogToConsole = 0\n",
    "        self.m.Params.Degenmoves=0\n",
    "        \n",
    "        # Optimize\n",
    "        self.total_objective = sum([o for o in self.objective])\n",
    "        self.m.setObjective(self.total_objective, GRB.MINIMIZE)\n",
    "        self.m.update()\n",
    "        \n",
    "        self.m.write(('mip_model_' + self.tree_name + '.lp'))\n",
    "        self.m.optimize()\n",
    "        \n",
    "        #Is feasible?\n",
    "        return self.m.SolCount > 0\n",
    "    \n",
    "    def get_info(self):\n",
    "        info_all = {}\n",
    "        info_all[\"objective\"] = self.m.ObjVal\n",
    "        info_all[\"bound\"] = self.m.ObjBound\n",
    "        info_all[\"gap\"] = self.m.MIPGap\n",
    "        info_all[\"is_optimal\"] = (self.m.status == GRB.OPTIMAL)\n",
    "        info_all[\"num_nodes\"] = self.m.NodeCount\n",
    "        info_all[\"num_vars\"] = self.m.NumIntVars + self.m.NumBinVars\n",
    "\n",
    "        if self.m.SolCount > 0:\n",
    "            print(\"objective: %0.2f\"%info_all[\"objective\"])\n",
    "            print(\"bound: %0.2f\"%info_all[\"bound\"])\n",
    "            print(\"gap: %0.2f\"%info_all[\"gap\"])\n",
    "\n",
    "        return info_all\n",
    "    \n",
    "    def get_solution(self):\n",
    "        \n",
    "        # get the path for extants - should be same as the input\n",
    "        all_node_paths = {}\n",
    "        for extant_info in self.extant_data:\n",
    "            sequence_name   = extant_info[1]\n",
    "            preferred_path = []\n",
    "            for pos in range(0,self.sequence_length):\n",
    "                pos_id = (sequence_name,pos)\n",
    "                preferred_path.append(int(self.positions[pos_id].X))\n",
    "            all_node_paths[sequence_name] = preferred_path\n",
    "        \n",
    "        # get the path for ancestor\n",
    "        for ancestor in self.ancestor_data[0]:\n",
    "            preferred_path = []\n",
    "            for pos in range(0,self.sequence_length):\n",
    "                pos_id = (ancestor,pos)\n",
    "                preferred_path.append(int(self.positions[pos_id].X))\n",
    "            all_node_paths[ancestor] = preferred_path\n",
    "            \n",
    "        # get the differnece and penalty solution\n",
    "        score_dict = {}\n",
    "        overall_score = 0\n",
    "        for node,node_neighbor in self.neighbor_dict.items():\n",
    "            for node_neighbor_item in node_neighbor:\n",
    "                total_score = 0\n",
    "                for pos in range(1,self.sequence_length - 1): # penalty start from 1st position only\n",
    "                    pen_id  = (node,node_neighbor_item,pos)\n",
    "                    diff_id = (node,node_neighbor_item,pos)\n",
    "                    \n",
    "                    total_score = total_score + 2 * int(self.penalty[pen_id].X)\n",
    "                    total_score = total_score + int(self.diff[diff_id].X)\n",
    "                    \n",
    "                score_dict[(node,node_neighbor_item)] = total_score\n",
    "                overall_score = overall_score + total_score\n",
    "        return all_node_paths,score_dict\n",
    "    \n",
    "    def output_fasta(self):\n",
    "        # convert output file to FASTA file\n",
    "        with open(self.mip_ancestor_fasta_file,mode='w') as fout:\n",
    "            for node_name,sequence in all_node_paths.items():\n",
    "                fout.write('>' + str(node_name) + '\\n')\n",
    "                sequence_str = ''.join([str(s) for s in sequence])\n",
    "                fout.write(str(sequence_str) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "2b1c8b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 1682337618.018334\n",
      "Set parameter Threads to value 1\n",
      "Set parameter TimeLimit to value 3600\n",
      "is_sat True\n",
      "-----------------------------\n",
      "Total time = 0.10[m]\n",
      "objective: 28.00\n",
      "bound: 28.00\n",
      "gap: 0.00\n",
      "info {'objective': 28.0, 'bound': 28.0, 'gap': 0.0, 'is_optimal': True, 'num_nodes': 1.0, 'num_vars': 4326, 'total_time': 0.10352516174316406, 'is_sat': True}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Start Time:\",start)\n",
    "n_threads = 1\n",
    "time_out = 60\n",
    "tree_name = 'sample1'\n",
    "# initialise the class\n",
    "PyTree = PhyloTreeMIP(extant_data,ancestor_data,tree_name,neighbor_dict)\n",
    "\n",
    "# variable and position constraints for extants\n",
    "PyTree.add_pos_constraints_extants()\n",
    "# variable and position constraints for ancestors\n",
    "PyTree.add_pos_constraints_ancestors()\n",
    "# variable and edge constraints for ancestors\n",
    "PyTree.add_edge_constraints_ancestors()\n",
    "# position difference constraints\n",
    "PyTree.add_penalty_constraint()\n",
    "\n",
    "is_sat = PyTree.train(n_threads, time_out)\n",
    "print(\"is_sat\",is_sat)\n",
    "total_time = ((time.time()-start))\n",
    "print(\"-----------------------------\")\n",
    "print(\"Total time = %0.2f[m]\"%total_time)\n",
    "info = PyTree.get_info()\n",
    "info[\"total_time\"] = total_time\n",
    "info[\"is_sat\"] = is_sat\n",
    "print(\"info\",info)\n",
    "\n",
    "if is_sat:\n",
    "    all_node_paths,score_dict = PyTree.get_solution()\n",
    "    #PyTree.output_fasta()\n",
    "else:\n",
    "    print(\"Did not find any satisfactory solution to the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f24c031d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A3': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " 'A9': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " 'A4': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       " 'A20': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1],\n",
       " 'A8': [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1],\n",
       " 'A5': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A19': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A1': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A17': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A10': [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
       " 'A7': [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A16': [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1],\n",
       " 'A18': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A13': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A15': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A14': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A11': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A12': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A2': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
       " 'A6': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1],\n",
       " 'NODE_0': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_1': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_2': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_3': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0],\n",
       " 'NODE_4': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_5': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_6': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_7': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0],\n",
       " 'NODE_8': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0],\n",
       " 'NODE_9': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_10': [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_11': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_12': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0],\n",
       " 'NODE_13': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_14': [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_15': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_16': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_17': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       " 'NODE_18': [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0]}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_node_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e7929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
