{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f5119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import gurobipy as gp\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from ete3 import Tree\n",
    "import numpy as np\n",
    "from pysam import FastaFile,FastxFile\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a6bf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch dataset to save the extant data\n",
    "class AjMat_Dataset(Dataset):\n",
    "    def __init__(self,adj_mat,seq_name,seq_binary):\n",
    "        self.adj_mat = adj_mat\n",
    "        self.seq_name = seq_name\n",
    "        self.seq_binary = seq_binary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adj_mat)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.adj_mat[idx],self.seq_name[idx],self.seq_binary[idx]\n",
    "\n",
    "\n",
    "# pytorch dataset to save the extant data\n",
    "class AjMat_lean_Dataset(Dataset):\n",
    "    def __init__(self,seq_name,seq_binary):\n",
    "        self.seq_name = seq_name\n",
    "        self.seq_binary = seq_binary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_name)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq_name[idx],self.seq_binary[idx]\n",
    "\n",
    "class IndelsInfo:\n",
    "    def __init__(self,AjMat_Dataset,fasta_file,nwk_file_path,folder_location,tree_name,AjMat_lean_Dataset):\n",
    "\n",
    "        self.AjMat_Dataset = AjMat_Dataset\n",
    "        self.input_file = fasta_file\n",
    "        self.nwk_file_path = nwk_file_path\n",
    "        self.ancestor_list = []\n",
    "        self.tree_neighbor_dict = defaultdict(list)\n",
    "        self.ancestor_info = []\n",
    "        self.sequence_length = 0\n",
    "        self.Extant_AdjMat_dataset = AjMat_Dataset\n",
    "        self.folder_location = folder_location\n",
    "        self.tree_name = tree_name\n",
    "        self.AjMat_lean_Dataset = AjMat_lean_Dataset\n",
    "        self.extant_dict = {}\n",
    "\n",
    "\n",
    "    # create node types for each position for each sequences\n",
    "    def create_node_type(self, seq_fwd_pog,seq_rvs_pog,seq_name):\n",
    "        node_type_dict = defaultdict(list)\n",
    "        node_type_dict[(seq_name,'start')] = [0]\n",
    "        node_type_dict[(seq_name,'end')] = [self.sequence_length - 1]\n",
    "\n",
    "        for n in range(1,self.sequence_length - 1):\n",
    "            if n in seq_fwd_pog.keys() and n in seq_rvs_pog.keys(): #if node has forward and backward\n",
    "                node_type_dict[(seq_name,'fwd_back_pos')] += [n]\n",
    "            elif n in seq_fwd_pog.keys() and n not in seq_rvs_pog.keys():\n",
    "                node_type_dict[(seq_name,'fwd_pos')] += [n]\n",
    "            elif n not in seq_fwd_pog.keys() and n in seq_rvs_pog.keys():\n",
    "                node_type_dict[(seq_name,'back_pos')] += [n]\n",
    "            else:\n",
    "                node_type_dict[(seq_name,'dead_pos')] += [n]\n",
    "        return node_type_dict\n",
    "\n",
    "    # function to find next position that is filled\n",
    "    def next_pos(self,str1,curr_pos,seq_len):\n",
    "        start_pos = curr_pos + 1\n",
    "\n",
    "        while(start_pos < len(str1)):\n",
    "            if str1[start_pos] != '-':\n",
    "                return start_pos\n",
    "            else:\n",
    "                start_pos = start_pos + 1\n",
    "        return seq_len\n",
    "\n",
    "    # function to convert a sequence to adj matrix\n",
    "    def convert_to_adj_mat(self,seq_str):\n",
    "        seq_len = len(seq_str)\n",
    "        aj_mat_array = np.zeros((seq_len,seq_len))\n",
    "\n",
    "        next_filled = []\n",
    "        ind = 0\n",
    "\n",
    "        while(ind < seq_len - 1):\n",
    "            if seq_str[ind] != '-':\n",
    "                curr_ind = ind\n",
    "                ind = self.next_pos(seq_str,curr_ind,seq_len - 1) # find the next filled position\n",
    "                next_filled.append((curr_ind,ind))\n",
    "                aj_mat_array[curr_ind,ind] = 1\n",
    "            else:\n",
    "                ind = ind + 1\n",
    "        return aj_mat_array\n",
    "\n",
    "    # convert adj matrix into pog dictionary\n",
    "    def create_extant_pog(self,adj_mat_t):\n",
    "        x_summ = np.column_stack(np.where(adj_mat_t))\n",
    "        seq_fwd_pog_dict = dict(zip(x_summ[:,0], x_summ[:,1]))\n",
    "        seq_rvs_pog_dict = dict(zip(x_summ[:,1], x_summ[:,0]))\n",
    "        return seq_fwd_pog_dict,seq_rvs_pog_dict\n",
    "\n",
    "    # 1 - convert fasta file to adj matrix, pog, node type, seq binary into pytorch dataset\n",
    "    def get_extant_data(self):\n",
    "        adj_mat_list      = []\n",
    "        seq_name_list     = []\n",
    "        seq_binary_list   = []\n",
    "\n",
    "\n",
    "        with FastxFile(self.input_file) as fh:\n",
    "            for entry in fh:\n",
    "                # add start and end string to the sequence\n",
    "                seq_name = entry.name\n",
    "                new_sequence = 'x' + entry.sequence + 'x'\n",
    "                self.sequence_length = len(new_sequence)\n",
    "\n",
    "                # convert to adj matrix\n",
    "                seq_adj_mat  = self.convert_to_adj_mat(new_sequence)\n",
    "\n",
    "                # binarise sequences\n",
    "                seq_binary   = ''.join(sum(seq_adj_mat).astype(int).astype(str))\n",
    "                # make start pos as 1 for start node\n",
    "                seq_binary = '1' + seq_binary[1:]\n",
    "\n",
    "                # convert to pog structure\n",
    "                seq_fwd_pog,seq_rvs_pog = self.create_extant_pog(seq_adj_mat)\n",
    "\n",
    "                # create node type dict\n",
    "                node_type = self.create_node_type(seq_fwd_pog,seq_rvs_pog,seq_name)\n",
    "\n",
    "                # add to the list\n",
    "                #adj_mat_t = torch.from_numpy(seq_adj_mat)\n",
    "                adj_mat_list.append(seq_adj_mat)\n",
    "                seq_name_list.append(seq_name)\n",
    "                seq_binary_list.append(seq_binary)\n",
    "\n",
    "        # save it into pytorch dataset\n",
    "        self.Extant_AdjMat_dataset = self.AjMat_Dataset(adj_mat_list, seq_name_list, seq_binary_list)\n",
    "        self.AjMat_lean_Dataset = self.AjMat_lean_Dataset(seq_name_list, seq_binary_list)\n",
    "        self.extant_dict = dict(zip(seq_name_list, seq_binary_list))\n",
    "\n",
    "        return self.Extant_AdjMat_dataset,self.AjMat_lean_Dataset,self.extant_dict\n",
    "\n",
    "    # 2 - create neighbour dict using the tree file\n",
    "    def get_tree_data(self):\n",
    "\n",
    "        ''' create neighbor dict '''\n",
    "        tree_file = open(self.nwk_file_path,\"r\")\n",
    "        my_tree = tree_file.read() + \";\"\n",
    "        tree = Tree(my_tree, format=1)\n",
    "\n",
    "        # add node names to the internal branches\n",
    "        edge = 0\n",
    "        for n in tree.traverse():\n",
    "            if not n.is_leaf():\n",
    "                n.name = \"NODE_%d\" %edge\n",
    "                edge += 1\n",
    "                self.ancestor_list.append(n.name)\n",
    "\n",
    "        # create neighbourhood object\n",
    "        for n in tree.traverse():\n",
    "            if n.is_leaf() == False:\n",
    "                for c in n.children:\n",
    "                    self.tree_neighbor_dict[n.name] += [c.name]\n",
    "\n",
    "        return self.tree_neighbor_dict\n",
    "\n",
    "    # 3 - ancestor data - all ancestors, aggregated pog, aggregated adj mat\n",
    "    def get_ancestor_data(self):\n",
    "\n",
    "        # all ancestors name\n",
    "        ancestor_branchpoints = self.ancestor_list\n",
    "\n",
    "        ancestor_fwd_pog = defaultdict(list)\n",
    "        ancestor_rvs_pog = defaultdict(list)\n",
    "\n",
    "        # ancestor adj mat\n",
    "        ancestor_adj_mat = np.where(sum(self.Extant_AdjMat_dataset[:][0]))\n",
    "\n",
    "        # ancestor foward and backward pog\n",
    "        row_col_sum = np.column_stack(np.where(sum(self.Extant_AdjMat_dataset[:][0])))\n",
    "        for r in row_col_sum:\n",
    "            pos = r[0]\n",
    "            next_pos = r[1]\n",
    "            ancestor_fwd_pog[pos] += [next_pos]\n",
    "            ancestor_rvs_pog[next_pos] += [pos]\n",
    "\n",
    "        # create node type dict\n",
    "        ancestor_node_type = self.create_node_type(ancestor_fwd_pog,ancestor_rvs_pog,'ANCESTOR')\n",
    "        self.ancestor_info = [ancestor_branchpoints,ancestor_fwd_pog,ancestor_rvs_pog,ancestor_node_type]\n",
    "        return self.ancestor_info\n",
    "\n",
    "    # save Dataset\n",
    "    def save_data(self):\n",
    "        # neighbor dict\n",
    "        with open(self.folder_location + self.tree_name + '/neighbor_dict.pkl','wb') as f:\n",
    "            pickle.dump(self.tree_neighbor_dict,f)\n",
    "        # ancestor Info\n",
    "        with open(self.folder_location + self.tree_name + '/ancestor_info.pkl','wb') as f:\n",
    "            pickle.dump(self.ancestor_info,f)\n",
    "        # extant info\n",
    "        print(self.extant_dict)\n",
    "        with open(self.folder_location + self.tree_name + '/extant_data.pkl','wb') as f:\n",
    "            pickle.dump(self.extant_dict,f)\n",
    "\n",
    "\n",
    "def main():\n",
    "    folder_location         = '/Users/sanjanatule/Documents/uq/Projects/MIPIndel/data/'\n",
    "    #folder_location         = '/media/WorkingSpace/Share/mipindel/data/'\n",
    "\n",
    "    ## Sample tree 1\n",
    "    tree_name               = 'st1'\n",
    "    nwk_file_path           = folder_location + tree_name + '/input_tree.nwk'\n",
    "    extant_sequence_file    = folder_location + tree_name + '/input_extants.fasta'\n",
    "\n",
    "    ## CYP2U - 165\n",
    "    #tree_name = 'CYP2U_165'\n",
    "    #nwk_file_path           = folder_location + tree_name + '/CYP2U_165.nwk'\n",
    "    #extant_sequence_file    = folder_location + tree_name + '/CYP2U_165.aln'\n",
    "\n",
    "    # ## CYP2U - 359\n",
    "    # tree_name = 'CYP2U_359'\n",
    "    # nwk_file_path           = folder_location + tree_name + '/CYP2U_359.nwk'\n",
    "    # extant_sequence_file    = folder_location + tree_name + '/CYP2U_359.aln'\n",
    "\n",
    "    # ## DHAD - 1612\n",
    "    # tree_name = 'DHAD_1612'\n",
    "    # nwk_file_path           = folder_location + tree_name + '/DHAD_1612.nwk'\n",
    "    # extant_sequence_file    = folder_location + tree_name + '/DHAD_1612.aln'\n",
    "\n",
    "    ## MBL\n",
    "    # tree_name = 'MBL'\n",
    "    # nwk_file_path           = folder_location + tree_name + '/nuclease_filt_i10.aln.treefile.nwk'\n",
    "    # extant_sequence_file    = folder_location + tree_name + '/nuclease_filt_i10.aln'\n",
    "\n",
    "    # CYPU - Anthony\n",
    "    # tree_name = 'anthony'\n",
    "    # nwk_file_path           = folder_location + tree_name + '/CYP19_Putative_6_DASH.nwk'\n",
    "    # extant_sequence_file    = folder_location + tree_name + '/CYP19_Putative_6_DASH.fasta'\n",
    "\n",
    "    # prepare input Dataset\n",
    "    print(\"Processing Input Files\")\n",
    "    MIPIndel      = IndelsInfo(AjMat_Dataset,extant_sequence_file,nwk_file_path,folder_location,tree_name,AjMat_lean_Dataset) # class\n",
    "    print(\"1 - Processing Extant Data\")\n",
    "    extant_data,extant_info_lean,extant_dict = MIPIndel.get_extant_data() # pog, adj matrix, binary, node type, sequence name\n",
    "    print(\"2 - Preparing Tree Data\")\n",
    "    neighbor_dict = MIPIndel.get_tree_data() # neighbor info\n",
    "    print(\"3 - Preparing Ancestor Data\")\n",
    "    ancestor_data = MIPIndel.get_ancestor_data() # ancestor list, ancestor pog, node type\n",
    "    print(\"4 - Saving Data\")\n",
    "    MIPIndel.save_data() # save data\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Info about the data\n",
    "    total_sequences = len(ancestor_data[0]) + 1\n",
    "    print(\"TOTAL EXTANT SEQUENCES\",total_sequences)\n",
    "    print(\"SEQUENCE LENGTH\",len(extant_info_lean[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2280bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Input Files\n",
      "1 - Processing Extant Data\n",
      "2 - Preparing Tree Data\n",
      "3 - Preparing Ancestor Data\n",
      "4 - Saving Data\n",
      "{'A3': '1101111100111111', 'A9': '1101111100111111', 'A4': '1101111100111111', 'A20': '1101111100111011', 'A8': '1000111100111011', 'A5': '1101111100101111', 'A19': '1101111100101111', 'A1': '1101111100101111', 'A17': '1101111100101111', 'A10': '1011111111101111', 'A7': '1011111110101111', 'A16': '1011111110100111', 'A18': '1101111100101111', 'A13': '1101111100101111', 'A15': '1101111100101111', 'A14': '1101111100101111', 'A11': '1101111100101111', 'A12': '1101111100101111', 'A2': '1101111100101111', 'A6': '1101111100101011'}\n",
      "Done\n",
      "TOTAL EXTANT SEQUENCES 20\n",
      "SEQUENCE LENGTH 16\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
